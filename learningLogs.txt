I started this project as my final project of "CUDA at Scale for the Enterprise" course with the requirement of processing a large volume of images efficientl. SO i starting first by tackling the task of reading and writing a single grayscale PGM image file using standard C++ on the CPU. 
Then I focused on the essential CUDA runtime API mechanics of allocating device memory and transferring that single image's data between the host and the device.

This was more comples because of writing custom filter kernels, the next step was to explore and integrate the NVIDIA Performance Primitives (NPP) which is a library requiring very very big learning curve because it required understanding its specific API for contexts, data structures, and function calls to successfully apply pre-optimized filters like the Box, Gaussian, and Sobel filters to the image now on the GPU. 
Now since the single-image GPU pipeline was complete, remaining task was meet the core batch processing requirement, this involved developing a system to automatically discover and iterate through all image files within an input directory, and then apply the  GPU-accelerated workflow to each one sequentially. 

Finally, to ensure the project was reproducible, and easy for a reviewer to evaluate, I started documentation by including a `Makefile` to manage the complex CUDA compilation flags and library linking, a user-friendly `run.sh` script for straightforward execution, and a helper Python script to procedurally generate a diverse set of test images, culminating in a well-documented and fully functional batch processing solution that demonstrates a comprehensive, step-by-step mastery of the development cycle.